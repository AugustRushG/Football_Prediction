{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE,mutual_info_classif\n",
    "from numpy import mean, std\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = range(2010,2023)\n",
    "team_seasons = range(2009,2023)\n",
    "premier_match_data = {}\n",
    "premier_team_data = {}\n",
    "premier_player_data = {}\n",
    "championship_match_data = {}\n",
    "championship_team_data = {}\n",
    "merge_premier={}\n",
    "merge_championship={}\n",
    "all_match_data = {}\n",
    "\n",
    "for i in team_seasons:\n",
    "    team_data_file = f'..//data//england_premier_team//england-premier-league-teams-{i}-to-{i+1}-stats.csv'\n",
    "    championship_team_data_file = f'..//data//england_championship_team//england-championship-teams-{i}-to-{i+1}-stats.csv'\n",
    "    championship_team_data[f'{i}_{i+1}'] = pd.read_csv(championship_team_data_file)\n",
    "    premier_team_data[f'{i}_{i+1}'] = pd.read_csv(team_data_file)\n",
    "\n",
    "for i in seasons:\n",
    "    match_data_file = f'..//data//england_premier_match//england-premier-league-matches-{i}-to-{i+1}-stats.csv'\n",
    "    player_data_file = f'..//data//england_premier_player//england-premier-league-players-{i}-to-{i+1}-stats.csv'\n",
    "    championship_match_data_file =  f'..//data//england_championship_match//england-championship-matches-{i}-to-{i+1}-stats.csv'\n",
    "    \n",
    "\n",
    "    premier_match_data[f'{i}_{i+1}'] = pd.read_csv(match_data_file)\n",
    "    premier_player_data[f'{i}_{i+1}'] = pd.read_csv(player_data_file)\n",
    "    championship_match_data[f'{i}_{i+1}'] = pd.read_csv(championship_match_data_file)\n",
    "    \n",
    "    merge_premier[f'{i}_{i+1}'] = premier_match_data[f'{i}_{i+1}'].merge(premier_team_data[f'{i-1}_{i}'], left_on ='home_team_name',right_on = 'common_name',suffixes=('', '_home'))\n",
    "    merge_championship[f'{i}_{i+1}'] = championship_match_data[f'{i}_{i+1}'].merge(championship_team_data[f'{i-1}_{i}'], left_on ='home_team_name',right_on = 'common_name',suffixes=('', '_home'))\n",
    "\n",
    "    all_match_data[f'{i}_{i+1}'] = pd.concat([merge_premier[f'{i}_{i+1}'], merge_championship[f'{i}_{i+1}']], ignore_index=True)\n",
    "    all_match_data[f'{i}_{i+1}'] = all_match_data[f'{i}_{i+1}'].loc[:, ~all_match_data[f'{i}_{i+1}'].columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_match_data['2013_2014'].to_csv(\"merge.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing data\n",
    "1. fill all missing value with -1 \n",
    "2. Split goal scoring minutes into first half and second half\n",
    "3. label encoding all object column\n",
    "4. group previous three matches as the feature to train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_goal_timings(goal_timings):\n",
    "    # Parse the string into a list of integers\n",
    "    if not isinstance(goal_timings, str):\n",
    "        return (0,0)  # Return (0,0) if goal_timings is not a string\n",
    "\n",
    "    if goal_timings=='-1':\n",
    "        return (0,0)\n",
    "    # Split the string into a list of times\n",
    "    goal_times = goal_timings.split(',')\n",
    "\n",
    "    first_half_goals = 0\n",
    "    second_half_goals = 0\n",
    "\n",
    "    for time in goal_times:\n",
    "        # Check if it's stoppage time\n",
    "        if \"'\" in time:\n",
    "            time_parts = time.split(\"'\")\n",
    "            # Consider stoppage time as part of the second half\n",
    "            if int(time_parts[0]) >= 45:\n",
    "                second_half_goals += 1\n",
    "        else:\n",
    "            # Check if the goal was scored in the first or second half\n",
    "            if int(time) <= 45:\n",
    "                first_half_goals += 1\n",
    "            else:\n",
    "                second_half_goals += 1\n",
    "    return first_half_goals, second_half_goals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all team names across all seasons\n",
    "all_teams = []\n",
    "all_referee = []\n",
    "all_stadiums = []\n",
    "for season in all_match_data.keys():\n",
    "    all_teams.extend(list(all_match_data[season]['home_team_name'].unique()))\n",
    "    all_teams.extend(list(all_match_data[season]['away_team_name'].unique()))\n",
    "    all_referee.extend(list(all_match_data[season]['referee'].unique()))\n",
    "  \n",
    "    all_stadiums.extend(list(all_match_data[season]['stadium_name'].unique()))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      108\n",
       "1      108\n",
       "2      108\n",
       "3      108\n",
       "4      108\n",
       "      ... \n",
       "737    115\n",
       "738    115\n",
       "739    115\n",
       "740    115\n",
       "741    115\n",
       "Name: total_goal_count_home, Length: 742, dtype: int64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_match_data['2010_2011']['total_goal_count_home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le_teams = LabelEncoder()\n",
    "le_referee = LabelEncoder()\n",
    "le_stadium = LabelEncoder()\n",
    "\n",
    "le_teams.fit(all_teams)\n",
    "le_referee.fit(all_referee)\n",
    "le_stadium.fit(all_stadiums)\n",
    "\n",
    "\n",
    "avoid_column = ['home_team_name','away_team_name','referee','stadium_name']\n",
    "drop_column  = ['team_name','common_name','country','season']\n",
    "for season, df in all_match_data.items():\n",
    "    df.drop(drop_column, axis=1)\n",
    "    # Transform teams\n",
    "    df['home_team_name'] = le_teams.transform(df['home_team_name'])\n",
    "    df['away_team_name'] = le_teams.transform(df['away_team_name'])\n",
    "    df['referee'] = le_referee.transform(df['referee'])\n",
    "    df['stadium_name'] = le_stadium.transform(df['stadium_name'])\n",
    "\n",
    "    all_match_data[season] = df.fillna(-1,inplace=True)\n",
    "    # Convert the column to string type\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col not in avoid_column:\n",
    "            # Convert the column to string type\n",
    "            df[col] = df[col].astype(str)\n",
    "            \n",
    "            # Apply the label encoder\n",
    "            le.fit(df[col])\n",
    "            df[col] = le.transform(df[col])\n",
    "\n",
    "    \n",
    "    all_match_data[season] = df\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to group previous 3 game stats as features of this game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_stats(group, window_size=3):\n",
    "    # List of columns to skip\n",
    "    columns_to_skip = ['timestamp', 'date_GMT', 'status', 'home_team_name', 'away_team_name', 'referee', 'Game Week']\n",
    "    group = group.sort_values('Game Week')\n",
    "    \n",
    "    # Shift the data down 1 so the current game's stats aren't included\n",
    "    group = group.shift(1)\n",
    "    \n",
    "    # Iterate over all columns in the group\n",
    "    for col in group.columns:\n",
    "        # Skip the column if it is in the list of columns to skip\n",
    "        if col not in columns_to_skip:\n",
    "            # The rolling window size is 3, which means the previous 3 games\n",
    "            group['rolling_avg_' + col] = group[col].rolling(window=window_size).mean()\n",
    "\n",
    "    # Drop the first two rows (which won't have any rolling data)\n",
    "    group = group.iloc[window_size:]\n",
    "    \n",
    "    return group\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all rolling data and remove those without. \n",
    "Leave the 2022-23 as a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to hold the stats for all seasons\n",
    "all_seasons_home_stats = {}\n",
    "all_seasons_away_stats = {}\n",
    "\n",
    "# Get a list of all season keys, sorted in ascending order\n",
    "seasons = sorted(all_match_data.keys())\n",
    "window_size = 2\n",
    "# Use all seasons except the last one\n",
    "for season in seasons[:-1]:\n",
    "    # Apply the calculate_rolling_stats function to the home and away data for this season\n",
    "    all_seasons_home_stats[season] = all_match_data[season].groupby('home_team_name').apply(calculate_rolling_stats,window_size)\n",
    "    all_seasons_away_stats[season] = all_match_data[season].groupby('away_team_name').apply(calculate_rolling_stats,window_size)\n",
    "\n",
    "# Convert the dictionaries to dataframes\n",
    "all_seasons_home_stats_df = pd.concat(all_seasons_home_stats, keys=all_seasons_home_stats.keys())\n",
    "all_seasons_away_stats_df = pd.concat(all_seasons_away_stats, keys=all_seasons_away_stats.keys())\n",
    "\n",
    "# Now, the last season's data can be accessed separately like this\n",
    "last_season_home_stats = all_match_data[seasons[-1]].groupby('home_team_name').apply(calculate_rolling_stats,window_size)\n",
    "last_season_away_stats = all_match_data[seasons[-1]].groupby('away_team_name').apply(calculate_rolling_stats,window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons_home_stats_df.to_csv(\"all_season_home.csv\", index=False)\n",
    "all_seasons_away_stats_df.to_csv(\"all_season_away.csv\", index=False)\n",
    "last_season_home_stats.to_csv(\"validation_home_stats.csv\", index=False)\n",
    "last_season_away_stats.to_csv(\"validation_away_stats.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_goals = all_seasons_home_stats_df['home_team_goal_count']\n",
    "away_goals = all_seasons_away_stats_df['away_team_goal_count']\n",
    "\n",
    "columns_to_drop_home = ['home_team_goal_count','total_goal_count','total_goals_at_half_time','home_team_goal_count_half_time','away_team_goal_count_half_time','home_team_goal_timings'\n",
    "                   ,'away_team_goal_timings','home_team_corner_count','away_team_corner_count','home_team_yellow_cards','home_team_red_cards','away_team_yellow_cards','away_team_red_cards',\n",
    "                   'home_team_first_half_cards','home_team_second_half_cards','away_team_first_half_cards','away_team_second_half_cards','home_team_shots','away_team_shots','home_team_shots_on_target',\n",
    "                   'away_team_shots_on_target','home_team_shots_off_target','away_team_shots_off_target','home_team_fouls','away_team_fouls','home_team_possession','away_team_possession',\n",
    "                   'status','attendance']\n",
    "\n",
    "columns_to_drop_away = ['away_team_goal_count','total_goal_count','total_goals_at_half_time','home_team_goal_count_half_time','away_team_goal_count_half_time','home_team_goal_timings'\n",
    "                   ,'away_team_goal_timings','home_team_corner_count','away_team_corner_count','home_team_yellow_cards','home_team_red_cards','away_team_yellow_cards','away_team_red_cards',\n",
    "                   'home_team_first_half_cards','home_team_second_half_cards','away_team_first_half_cards','away_team_second_half_cards','home_team_shots','away_team_shots','home_team_shots_on_target',\n",
    "                   'away_team_shots_on_target','home_team_shots_off_target','away_team_shots_off_target','home_team_fouls','away_team_fouls','home_team_possession','away_team_possession',\n",
    "                   'status','attendance']\n",
    "\n",
    "# Drop these columns from the predictor variables DataFrame\n",
    "y_home = all_seasons_home_stats_df['home_team_goal_count']\n",
    "y_away = all_seasons_away_stats_df['away_team_goal_count']\n",
    "X_home = all_seasons_home_stats_df.drop(columns_to_drop_home, axis=1)\n",
    "X_away = all_seasons_away_stats_df.drop(columns_to_drop_away, axis=1)\n",
    "test_home_X = last_season_home_stats.drop(columns_to_drop_home, axis=1)\n",
    "test_home_y = last_season_home_stats['home_team_goal_count']\n",
    "test_away_X = last_season_away_stats.drop(columns_to_drop_away, axis=1)\n",
    "test_away_y = last_season_away_stats['away_team_goal_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "}\n",
    "grid_params = {\n",
    "    \"Linear Regression\": {\n",
    "        'fit_intercept': [True, False],  # Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
    "        'max_depth': [None, 5, 10, 20, 30],  # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 5, 10],  # The minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 4],  # The minimum number of samples required to be at a leaf node\n",
    "        'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of boosting stages to perform\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Learning rate\n",
    "        'max_depth': [3, 5, 7, 10],  # Maximum depth of the individual regression estimators\n",
    "        'subsample': [0.5, 0.7, 1.0],  # The fraction of samples to be used for fitting the individual base learners\n",
    "        'min_samples_split': [2, 5, 10],  # The minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 4],  # The minimum number of samples required to be at a leaf node\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select most useful features\n",
    "1. note! after using mutual info it appears that less the feature selected, the worse the accuracy is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features_home:  Index(['home_ppg', 'away_ppg', 'team_a_xg', 'odds_ft_home_team_win',\n",
      "       'odds_ft_away_team_win', 'performance_rank', 'goal_difference',\n",
      "       'win_percentage_home', 'rolling_avg_home_ppg',\n",
      "       'rolling_avg_home_team_goal_count', 'rolling_avg_total_goal_count',\n",
      "       'rolling_avg_total_goals_at_half_time',\n",
      "       'rolling_avg_home_team_goal_count_half_time',\n",
      "       'rolling_avg_home_team_goal_timings',\n",
      "       'rolling_avg_home_team_shots_on_target',\n",
      "       'rolling_avg_odds_ft_home_team_win',\n",
      "       'rolling_avg_odds_ft_away_team_win', 'rolling_avg_stadium_name',\n",
      "       'rolling_avg_fts_half_time', 'rolling_avg_corners_per_match'],\n",
      "      dtype='object')\n",
      "Selected features_away:  Index(['home_ppg', 'away_ppg', 'team_b_xg', 'odds_ft_home_team_win',\n",
      "       'odds_ft_away_team_win', 'odds_btts_yes', 'stadium_name',\n",
      "       'goals_scored_home', 'shots_on_target_home', 'over05_percentage',\n",
      "       'rolling_avg_away_ppg', 'rolling_avg_away_team_goal_count',\n",
      "       'rolling_avg_total_goal_count', 'rolling_avg_total_goals_at_half_time',\n",
      "       'rolling_avg_away_team_goal_count_half_time',\n",
      "       'rolling_avg_away_team_goal_timings',\n",
      "       'rolling_avg_away_team_shots_on_target',\n",
      "       'rolling_avg_odds_ft_home_team_win', 'rolling_avg_odds_ft_over25',\n",
      "       'rolling_avg_wins_away'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(mutual_info_classif, k=20)\n",
    "selector.fit_transform(X_home, y_home)\n",
    "\n",
    "selected_features_home = selector.get_support(indices=True)\n",
    "print(\"Selected features_home: \", X_home.columns[selected_features_home])\n",
    "\n",
    "selector.fit_transform(X_away,y_away)\n",
    "selected_features_away = selector.get_support(indices=True)\n",
    "print(\"Selected features_away: \", X_away.columns[selected_features_away])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_param(X, y, models, cv=5):\n",
    "    best_models = {}\n",
    "    mse_scores = {}\n",
    "    for model_name, model in models.items():\n",
    "        # clf = GridSearchCV(model, grid_params[model_name], cv=cv, scoring='neg_mean_squared_error')\n",
    "        clf = RandomizedSearchCV(model, grid_params[model_name], cv=cv, scoring='neg_mean_squared_error', n_iter=100, random_state=42)\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        print(f\"Best parameters for {model_name}:\")\n",
    "        print(clf.best_params_)\n",
    "        best_models[model_name] = clf.best_estimator_\n",
    "\n",
    "        # Predict with cross validation and compute MSE\n",
    "        y_pred = cross_val_predict(clf.best_estimator_, X, y, cv=cv)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        mse_scores[model_name] = mse\n",
    "        print(f'MSE for {model_name}: {mse}')\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(mse_scores.keys(), mse_scores.values(), color='blue', alpha=0.6)\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title('Cross-validated MSE for different models')\n",
    "    plt.show()\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "\n",
    "def fit_and_compute_mse(models, X, y, selected_features = None, k=10):\n",
    "    mse_scores = {}\n",
    "    \n",
    "    X_selected = X if selected_features is None else X[X.columns[selected_features]]\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_selected, y, cv=k, scoring='neg_mean_squared_error')\n",
    "        # Take the negative of the scores to get the MSE\n",
    "        mse_scores[name] = -scores.mean()\n",
    "        print(f\"{name} loss is {-scores.mean()}\")\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(mse_scores.keys(), mse_scores.values(), color='blue', alpha=0.6)\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title('Cross-validated MSE for different models')\n",
    "    plt.show()\n",
    "\n",
    "def test_on_test(models,test_X,test_y):\n",
    "    mse_scores = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(test_X)\n",
    "        scores = mean_squared_error(y_pred=y_pred,y_true=test_y)\n",
    "        # Take the negative of the scores to get the MSE\n",
    "        mse_scores[name] = -scores.mean()\n",
    "        print(f\"{name} loss is {-scores.mean()}\")\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(mse_scores.keys(), mse_scores.values(), color='blue', alpha=0.6)\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title('MSE for test set')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xu741\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 2 is smaller than n_iter=100. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Linear Regression:\n",
      "{'fit_intercept': False}\n",
      "MSE for Linear Regression: 0.6627860170373007\n"
     ]
    }
   ],
   "source": [
    "home_best_estimator = find_best_param(X_home,y_home,models)\n",
    "away_best_estimator = find_best_param(X_away,y_away,models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
